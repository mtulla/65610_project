{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhu/Documents/code/ml/65610_project/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/davidhu/Documents/code/ml/65610_project/venv/lib/python3.10/site-packages/threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from concrete.ml.torch.compile import compile_brevitas_qat_model\n",
    "from mingpt.model import GPT\n",
    "from mingpt.utils import CfgNode as CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhegpt.qmodel import QuantCasualSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CN(\n",
    "    n_embd = 768,\n",
    "    n_layer = 12,\n",
    "    n_head=12,\n",
    "    attn_pdrop=0.1,\n",
    "    resid_pdrop=0.1,\n",
    "    embd_pdrop=0.1,\n",
    "    block_size=1000\n",
    ")\n",
    "qcsa = QuantCasualSelfAttention(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantCasualSelfAttention(\n",
      "  (quant_inp): QuantIdentity(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (c_attn1): QuantLinear(\n",
      "    in_features=768, out_features=768, bias=True\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "  )\n",
      "  (c_attn2): QuantLinear(\n",
      "    in_features=768, out_features=768, bias=True\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "  )\n",
      "  (c_attn3): QuantLinear(\n",
      "    in_features=768, out_features=768, bias=True\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "  )\n",
      "  (c_proj): QuantLinear(\n",
      "    in_features=768, out_features=768, bias=True\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "  )\n",
      "  (attn_dropout): QuantDropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): QuantDropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(qcsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size torch.Size([1, 10, 768])\n",
      "k size torch.Size([1, 12, 10, 64])\n",
      "att size torch.Size([1, 12, 10, 10])\n",
      "type:<built-in method type of Tensor object at 0x14f3f6840>\n",
      "tensor([[[[ 2.0398e-01,  1.7629e-02, -6.8057e-02,  ...,  7.7710e-02,\n",
      "           -1.8742e-01,  1.4398e-02],\n",
      "          [ 1.3464e-01,  2.3380e-02,  3.1497e-01,  ...,  5.3294e-02,\n",
      "           -1.7721e-01,  2.2448e-01],\n",
      "          [-5.8807e-02, -9.4393e-02, -9.4535e-02,  ..., -2.1856e-02,\n",
      "            1.1519e-01, -1.1417e-01],\n",
      "          ...,\n",
      "          [ 3.5671e-02, -1.8994e-01,  2.7274e-02,  ...,  1.8284e-01,\n",
      "            6.8152e-02,  3.6103e-02],\n",
      "          [-6.8179e-02,  5.0569e-02, -1.6007e-02,  ..., -8.6557e-02,\n",
      "            4.5674e-02, -1.9597e-01],\n",
      "          [ 1.8493e-03, -3.9756e-02,  2.7428e-01,  ...,  1.4109e-01,\n",
      "            4.3118e-02, -1.6142e-01]],\n",
      "\n",
      "         [[ 3.1261e-01,  2.3545e-01,  1.3841e-01,  ...,  1.3233e-01,\n",
      "           -2.0676e-01,  6.2819e-02],\n",
      "          [-1.5730e-01, -1.3279e-01,  2.4011e-01,  ...,  5.0064e-02,\n",
      "            4.7197e-03,  1.1009e-01],\n",
      "          [ 2.3283e-01,  3.5248e-02, -5.1509e-02,  ..., -4.9862e-01,\n",
      "           -4.1649e-01,  3.3945e-01],\n",
      "          ...,\n",
      "          [ 2.0167e-01,  1.1011e-01,  1.3722e-02,  ..., -2.3518e-01,\n",
      "           -1.2214e-01,  1.3948e-01],\n",
      "          [ 6.0506e-02,  1.7987e-01,  7.3462e-02,  ..., -9.8526e-04,\n",
      "           -2.1127e-01, -1.2854e-01],\n",
      "          [ 2.6041e-01, -3.3060e-04,  2.1299e-02,  ..., -1.8160e-01,\n",
      "            8.4923e-02,  1.5020e-02]],\n",
      "\n",
      "         [[ 5.0225e-02, -1.3378e-01,  9.0979e-02,  ...,  2.1189e-01,\n",
      "           -2.1525e-02,  8.9991e-02],\n",
      "          [ 1.1617e-01, -1.4809e-01,  1.5245e-01,  ...,  1.6321e-01,\n",
      "            1.9245e-02,  9.6441e-02],\n",
      "          [-4.2156e-01, -3.0353e-01,  9.3328e-02,  ...,  1.3184e-01,\n",
      "           -1.8933e-01,  1.8377e-01],\n",
      "          ...,\n",
      "          [-3.5173e-02, -1.0683e-01,  1.3729e-01,  ...,  8.6195e-02,\n",
      "            4.0354e-02,  1.0597e-02],\n",
      "          [ 2.2502e-02, -2.4067e-02, -2.7946e-01,  ..., -1.6249e-01,\n",
      "           -7.5693e-02,  9.9713e-02],\n",
      "          [-1.9283e-01,  5.7768e-02, -2.4015e-02,  ...,  1.0362e-01,\n",
      "            9.9441e-02,  1.8686e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.8442e-02,  1.3779e-02,  2.5896e-01,  ...,  1.4767e-01,\n",
      "           -5.1421e-02,  5.0732e-02],\n",
      "          [ 9.3872e-02,  6.5970e-02,  3.6975e-02,  ..., -1.9196e-02,\n",
      "           -1.9019e-01, -2.7863e-02],\n",
      "          [-1.7408e-01, -5.0039e-02, -2.1297e-02,  ...,  1.6544e-01,\n",
      "            9.8355e-02, -3.8367e-02],\n",
      "          ...,\n",
      "          [-3.9346e-02, -2.1281e-01, -1.2281e-01,  ...,  4.0288e-02,\n",
      "           -8.0717e-02, -1.4664e-02],\n",
      "          [-6.4059e-02,  4.0890e-03, -1.1851e-01,  ...,  1.0748e-01,\n",
      "            3.5267e-02, -2.5480e-01],\n",
      "          [ 1.0403e-01, -3.4556e-01, -7.2177e-02,  ...,  1.2090e-01,\n",
      "            3.1796e-01,  1.2994e-01]],\n",
      "\n",
      "         [[-1.9448e-01,  1.6142e-01,  1.0877e-01,  ...,  6.9817e-02,\n",
      "            2.4112e-02,  8.9512e-02],\n",
      "          [-1.5226e-01,  1.0603e-01, -1.3638e-01,  ...,  2.9455e-01,\n",
      "            6.4956e-02, -9.4791e-02],\n",
      "          [-2.4370e-01,  5.9287e-02,  1.6977e-01,  ...,  1.1450e-01,\n",
      "            8.7150e-03, -3.2246e-01],\n",
      "          ...,\n",
      "          [ 3.8922e-02, -7.4081e-02, -1.4982e-01,  ...,  4.3569e-02,\n",
      "            2.1969e-01, -1.7492e-01],\n",
      "          [-3.7834e-02, -6.8603e-02, -2.3937e-01,  ...,  1.3695e-01,\n",
      "            6.2877e-03, -3.6311e-03],\n",
      "          [-1.0402e-02, -9.3825e-02, -1.5727e-01,  ..., -9.6851e-02,\n",
      "           -1.3069e-01,  4.8817e-02]],\n",
      "\n",
      "         [[ 7.1792e-02,  8.3578e-02,  1.2040e-01,  ...,  2.6904e-03,\n",
      "            1.0417e-01,  5.9559e-02],\n",
      "          [ 1.3004e-01,  8.3142e-03,  8.6271e-02,  ..., -1.5642e-01,\n",
      "            2.6939e-02, -3.4904e-02],\n",
      "          [-7.1879e-02, -1.7751e-01,  4.9880e-02,  ..., -3.1446e-01,\n",
      "           -1.6753e-01,  3.5472e-02],\n",
      "          ...,\n",
      "          [ 3.9719e-02,  1.6978e-01, -1.8108e-01,  ...,  3.9713e-03,\n",
      "           -2.3685e-01, -9.4917e-02],\n",
      "          [-2.8187e-02,  2.0598e-01,  1.8984e-01,  ..., -2.0252e-01,\n",
      "           -2.4803e-01,  3.4517e-01],\n",
      "          [ 5.7126e-02, -2.0170e-01, -2.0392e-01,  ..., -7.3496e-02,\n",
      "            1.6873e-02, -2.8882e-01]]]])\n",
      "x size torch.Size([1, 10, 768])\n",
      "k size torch.Size([1, 12, 10, 64])\n",
      "att size torch.Size([1, 12, 10, 10])\n",
      "type:<built-in method type of Tensor object at 0x14f40e070>\n",
      "tensor([[[[ 2.0398e-01,  1.7629e-02, -6.8057e-02,  ...,  7.7710e-02,\n",
      "           -1.8742e-01,  1.4398e-02],\n",
      "          [ 1.3464e-01,  2.3380e-02,  3.1497e-01,  ...,  5.3294e-02,\n",
      "           -1.7721e-01,  2.2448e-01],\n",
      "          [-5.8807e-02, -9.4393e-02, -9.4535e-02,  ..., -2.1856e-02,\n",
      "            1.1519e-01, -1.1417e-01],\n",
      "          ...,\n",
      "          [ 3.5671e-02, -1.8994e-01,  2.7274e-02,  ...,  1.8284e-01,\n",
      "            6.8152e-02,  3.6103e-02],\n",
      "          [-6.8179e-02,  5.0569e-02, -1.6007e-02,  ..., -8.6557e-02,\n",
      "            4.5674e-02, -1.9597e-01],\n",
      "          [ 1.8493e-03, -3.9756e-02,  2.7428e-01,  ...,  1.4109e-01,\n",
      "            4.3118e-02, -1.6142e-01]],\n",
      "\n",
      "         [[ 3.1261e-01,  2.3545e-01,  1.3841e-01,  ...,  1.3233e-01,\n",
      "           -2.0676e-01,  6.2819e-02],\n",
      "          [-1.5730e-01, -1.3279e-01,  2.4011e-01,  ...,  5.0064e-02,\n",
      "            4.7197e-03,  1.1009e-01],\n",
      "          [ 2.3283e-01,  3.5248e-02, -5.1509e-02,  ..., -4.9862e-01,\n",
      "           -4.1649e-01,  3.3945e-01],\n",
      "          ...,\n",
      "          [ 2.0167e-01,  1.1011e-01,  1.3722e-02,  ..., -2.3518e-01,\n",
      "           -1.2214e-01,  1.3948e-01],\n",
      "          [ 6.0506e-02,  1.7987e-01,  7.3462e-02,  ..., -9.8526e-04,\n",
      "           -2.1127e-01, -1.2854e-01],\n",
      "          [ 2.6041e-01, -3.3060e-04,  2.1299e-02,  ..., -1.8160e-01,\n",
      "            8.4923e-02,  1.5020e-02]],\n",
      "\n",
      "         [[ 5.0225e-02, -1.3378e-01,  9.0979e-02,  ...,  2.1189e-01,\n",
      "           -2.1525e-02,  8.9991e-02],\n",
      "          [ 1.1617e-01, -1.4809e-01,  1.5245e-01,  ...,  1.6321e-01,\n",
      "            1.9245e-02,  9.6441e-02],\n",
      "          [-4.2156e-01, -3.0353e-01,  9.3328e-02,  ...,  1.3184e-01,\n",
      "           -1.8933e-01,  1.8377e-01],\n",
      "          ...,\n",
      "          [-3.5173e-02, -1.0683e-01,  1.3729e-01,  ...,  8.6195e-02,\n",
      "            4.0354e-02,  1.0597e-02],\n",
      "          [ 2.2502e-02, -2.4067e-02, -2.7946e-01,  ..., -1.6249e-01,\n",
      "           -7.5693e-02,  9.9713e-02],\n",
      "          [-1.9283e-01,  5.7768e-02, -2.4015e-02,  ...,  1.0362e-01,\n",
      "            9.9441e-02,  1.8686e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.8442e-02,  1.3779e-02,  2.5896e-01,  ...,  1.4767e-01,\n",
      "           -5.1421e-02,  5.0732e-02],\n",
      "          [ 9.3872e-02,  6.5970e-02,  3.6975e-02,  ..., -1.9196e-02,\n",
      "           -1.9019e-01, -2.7863e-02],\n",
      "          [-1.7408e-01, -5.0039e-02, -2.1297e-02,  ...,  1.6544e-01,\n",
      "            9.8355e-02, -3.8367e-02],\n",
      "          ...,\n",
      "          [-3.9346e-02, -2.1281e-01, -1.2281e-01,  ...,  4.0288e-02,\n",
      "           -8.0717e-02, -1.4664e-02],\n",
      "          [-6.4059e-02,  4.0890e-03, -1.1851e-01,  ...,  1.0748e-01,\n",
      "            3.5267e-02, -2.5480e-01],\n",
      "          [ 1.0403e-01, -3.4556e-01, -7.2177e-02,  ...,  1.2090e-01,\n",
      "            3.1796e-01,  1.2994e-01]],\n",
      "\n",
      "         [[-1.9448e-01,  1.6142e-01,  1.0877e-01,  ...,  6.9817e-02,\n",
      "            2.4112e-02,  8.9512e-02],\n",
      "          [-1.5226e-01,  1.0603e-01, -1.3638e-01,  ...,  2.9455e-01,\n",
      "            6.4956e-02, -9.4791e-02],\n",
      "          [-2.4370e-01,  5.9287e-02,  1.6977e-01,  ...,  1.1450e-01,\n",
      "            8.7150e-03, -3.2246e-01],\n",
      "          ...,\n",
      "          [ 3.8922e-02, -7.4081e-02, -1.4982e-01,  ...,  4.3569e-02,\n",
      "            2.1969e-01, -1.7492e-01],\n",
      "          [-3.7834e-02, -6.8603e-02, -2.3937e-01,  ...,  1.3695e-01,\n",
      "            6.2877e-03, -3.6311e-03],\n",
      "          [-1.0402e-02, -9.3825e-02, -1.5727e-01,  ..., -9.6851e-02,\n",
      "           -1.3069e-01,  4.8817e-02]],\n",
      "\n",
      "         [[ 7.1792e-02,  8.3578e-02,  1.2040e-01,  ...,  2.6904e-03,\n",
      "            1.0417e-01,  5.9559e-02],\n",
      "          [ 1.3004e-01,  8.3142e-03,  8.6271e-02,  ..., -1.5642e-01,\n",
      "            2.6939e-02, -3.4904e-02],\n",
      "          [-7.1879e-02, -1.7751e-01,  4.9880e-02,  ..., -3.1446e-01,\n",
      "           -1.6753e-01,  3.5472e-02],\n",
      "          ...,\n",
      "          [ 3.9719e-02,  1.6978e-01, -1.8108e-01,  ...,  3.9713e-03,\n",
      "           -2.3685e-01, -9.4917e-02],\n",
      "          [-2.8187e-02,  2.0598e-01,  1.8984e-01,  ..., -2.0252e-01,\n",
      "           -2.4803e-01,  3.4517e-01],\n",
      "          [ 5.7126e-02, -2.0170e-01, -2.0392e-01,  ..., -7.3496e-02,\n",
      "            1.6873e-02, -2.8882e-01]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhu/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/quantization/quantizers.py:497: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  if stats.rmax - stats.rmin < STABILITY_CONST:\n",
      "/Users/davidhu/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/onnx/ops_impl.py:149: RuntimeWarning: invalid value encountered in multiply\n",
      "  return c * t + (1.0 - c) * f\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "QuantizedOps whose ONNX numpy implementation is marked as producing raw output must return an instance of RawOpOutput. \n ** Offending Op: ONNXShape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m torch_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, config\u001b[38;5;241m.\u001b[39mn_embd)\n\u001b[0;32m----> 2\u001b[0m quantized_model \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_brevitas_qat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqcsa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/torch/compile.py:534\u001b[0m, in \u001b[0;36mcompile_brevitas_qat_model\u001b[0;34m(torch_model, torch_inputset, n_bits, configuration, artifacts, show_mlir, rounding_threshold_bits, p_error, global_p_error, output_onnx_file, verbose, inputs_encryption_status, reduce_sum_copy)\u001b[0m\n\u001b[1;32m    528\u001b[0m assert_true(\n\u001b[1;32m    529\u001b[0m     n_bits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n_bits, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mdict\u001b[39m)),\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe n_bits parameter must be either a dictionary, an integer or None\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    531\u001b[0m )\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# Compile using the ONNX conversion flow, in QAT mode\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m q_module \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_onnx_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_inputset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_qat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_mlir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_mlir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrounding_threshold_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrounding_threshold_bits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_p_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_p_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_encryption_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_encryption_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduce_sum_copy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_sum_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# Remove the tempfile if we used one\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_tempfile:\n",
      "File \u001b[0;32m~/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/torch/compile.py:383\u001b[0m, in \u001b[0;36mcompile_onnx_model\u001b[0;34m(onnx_model, torch_inputset, import_qat, configuration, artifacts, show_mlir, n_bits, rounding_threshold_bits, p_error, global_p_error, verbose, inputs_encryption_status, reduce_sum_copy)\u001b[0m\n\u001b[1;32m    376\u001b[0m onnx_model_opset_version \u001b[38;5;241m=\u001b[39m get_onnx_opset_version(onnx_model)\n\u001b[1;32m    377\u001b[0m assert_true(\n\u001b[1;32m    378\u001b[0m     onnx_model_opset_version \u001b[38;5;241m==\u001b[39m OPSET_VERSION_FOR_ONNX_EXPORT,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNX version must be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOPSET_VERSION_FOR_ONNX_EXPORT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut it is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx_model_opset_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m )\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_torch_or_onnx_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_inputset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_qat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_mlir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_mlir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrounding_threshold_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrounding_threshold_bits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_p_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_p_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_encryption_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_encryption_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduce_sum_copy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_sum_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/torch/compile.py:195\u001b[0m, in \u001b[0;36m_compile_torch_or_onnx_model\u001b[0;34m(model, torch_inputset, import_qat, configuration, artifacts, show_mlir, n_bits, rounding_threshold_bits, p_error, global_p_error, verbose, inputs_encryption_status, reduce_sum_copy)\u001b[0m\n\u001b[1;32m    190\u001b[0m inputset_as_numpy_tuple \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    191\u001b[0m     convert_torch_tensor_or_numpy_array_to_numpy_array(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m to_tuple(torch_inputset)\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Build the quantized module\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m quantized_module \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_quantized_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_inputset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputset_as_numpy_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_qat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimport_qat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrounding_threshold_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrounding_threshold_bits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduce_sum_copy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_sum_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Check that p_error or global_p_error is not set in both the configuration and in the direct\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# parameters\u001b[39;00m\n\u001b[1;32m    206\u001b[0m check_there_is_no_p_error_options_in_configuration(configuration)\n",
      "File \u001b[0;32m~/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/torch/compile.py:127\u001b[0m, in \u001b[0;36mbuild_quantized_module\u001b[0;34m(model, torch_inputset, import_qat, n_bits, rounding_threshold_bits, reduce_sum_copy)\u001b[0m\n\u001b[1;32m    121\u001b[0m post_training_quant \u001b[38;5;241m=\u001b[39m post_training(n_bits, numpy_model, rounding_threshold_bits)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Build the quantized module\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# FIXME: mismatch here. We traced with dummy_input_for_tracing which made some operator\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# only work over shape of (1, ., .). For example, some reshape have newshape hardcoded based\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# on the inputset we sent in the NumpyModule.\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m quantized_module \u001b[38;5;241m=\u001b[39m \u001b[43mpost_training_quant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputset_as_numpy_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# FIXME: https://github.com/zama-ai/concrete-ml-internal/issues/4127\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce_sum_copy:\n",
      "File \u001b[0;32m~/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/quantization/post_training.py:711\u001b[0m, in \u001b[0;36mONNXConverter.quantize_module\u001b[0;34m(self, *calibration_data)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;66;03m# First transform all parameters to their quantized version\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quantize_params()\n\u001b[0;32m--> 711\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quantize_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcalibration_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Create quantized module from self.quant_layers_dict\u001b[39;00m\n\u001b[1;32m    714\u001b[0m quantized_module \u001b[38;5;241m=\u001b[39m QuantizedModule(\n\u001b[1;32m    715\u001b[0m     ordered_module_input_names\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    716\u001b[0m         graph_input\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m graph_input \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_model\u001b[38;5;241m.\u001b[39monnx_model\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minput\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    722\u001b[0m     onnx_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_model\u001b[38;5;241m.\u001b[39monnx_model,\n\u001b[1;32m    723\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/quantization/post_training.py:638\u001b[0m, in \u001b[0;36mONNXConverter._quantize_layers\u001b[0;34m(self, *input_calibration_data)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_ops_dict[output_name] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(variable_input_names),\n\u001b[1;32m    631\u001b[0m     quantized_op_instance,\n\u001b[1;32m    632\u001b[0m )\n\u001b[1;32m    634\u001b[0m layer_quant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    635\u001b[0m     node_override_quantizer\u001b[38;5;241m.\u001b[39mget(input_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m variable_input_names\n\u001b[1;32m    637\u001b[0m )\n\u001b[0;32m--> 638\u001b[0m output_calibration_data, layer_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantized_op_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcurr_calibration_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_quant\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m node_results[output_name] \u001b[38;5;241m=\u001b[39m output_calibration_data\n\u001b[1;32m    642\u001b[0m node_override_quantizer[output_name] \u001b[38;5;241m=\u001b[39m layer_quantizer\n",
      "File \u001b[0;32m~/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/quantization/post_training.py:1013\u001b[0m, in \u001b[0;36mPostTrainingQATImporter._process_layer\u001b[0;34m(self, quantized_op, quantizers, *calibration_data)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_layer\u001b[39m(\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    994\u001b[0m     quantized_op: QuantizedOp,\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;241m*\u001b[39mcalibration_data: numpy\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m    996\u001b[0m     quantizers: List[Optional[UniformQuantizer]],\n\u001b[1;32m    997\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[numpy\u001b[38;5;241m.\u001b[39mndarray, Optional[UniformQuantizer]]:\n\u001b[1;32m    998\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Configure a graph operation by calibrating it for Quantization Aware Training.\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \n\u001b[1;32m   1000\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03m        numpy.ndarray: calibration data for the following operators\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calibrate_layers_activation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantized_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcalibration_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantizers\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/quantization/post_training.py:395\u001b[0m, in \u001b[0;36mONNXConverter._calibrate_layers_activation\u001b[0;34m(self, calibrate_quantized, quantized_op, quantizers, *calibration_data)\u001b[0m\n\u001b[1;32m    392\u001b[0m     quantized_op\u001b[38;5;241m.\u001b[39moutput_quant_stats\u001b[38;5;241m.\u001b[39mcopy_stats(quant_result\u001b[38;5;241m.\u001b[39mquantizer\u001b[38;5;241m.\u001b[39mquant_stats)\n\u001b[1;32m    393\u001b[0m     quantized_op\u001b[38;5;241m.\u001b[39moutput_quant_params\u001b[38;5;241m.\u001b[39mcopy_params(quant_result\u001b[38;5;241m.\u001b[39mquantizer\u001b[38;5;241m.\u001b[39mquant_params)\n\u001b[0;32m--> 395\u001b[0m \u001b[43massert_true\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquantized_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduces_raw_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquant_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRawOpOutput\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuantizedOps whose ONNX numpy implementation is marked as producing raw output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m must return an instance of RawOpOutput. \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m ** Offending Op: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquantized_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# For PTQ, the calibration is performed on quantized data. But\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# raw operation output (RawOpOutput) data should not be quantized\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calibrate_quantized \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(quant_result, RawOpOutput):\n",
      "File \u001b[0;32m~/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/common/debugging/custom_assert.py:41\u001b[0m, in \u001b[0;36massert_true\u001b[0;34m(condition, on_error_msg, error_type)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_true\u001b[39m(\n\u001b[1;32m     30\u001b[0m     condition: \u001b[38;5;28mbool\u001b[39m, on_error_msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, error_type: Type[\u001b[38;5;167;01mException\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAssertionError\u001b[39;00m\n\u001b[1;32m     31\u001b[0m ):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Provide a custom assert to check that the condition is True.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[43m_custom_assert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error_msg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/ml/65610_project/concrete-ml/src/concrete/ml/common/debugging/custom_assert.py:26\u001b[0m, in \u001b[0;36m_custom_assert\u001b[0;34m(condition, on_error_msg, error_type)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Provide a custom assert which is kept even if the optimized Python mode is used.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mSee https://docs.python.org/3/reference/simple_stmts.html#assert for the documentation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m condition:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_type(on_error_msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: QuantizedOps whose ONNX numpy implementation is marked as producing raw output must return an instance of RawOpOutput. \n ** Offending Op: ONNXShape"
     ]
    }
   ],
   "source": [
    "torch_input = torch.randn(1, 10, config.n_embd)\n",
    "quantized_model = compile_brevitas_qat_model(qcsa, torch_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
